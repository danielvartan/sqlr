temp <- dplyr::select(x, provider, source_id, search_id)
temp <- tail(temp)
temp <- dplyr::select(x, provider, source_id, search_id)
temp <- head(temp)
x <- tidy_reference(raw, quiet)
x <- raw
checkmate::assert_data_frame(x, min.rows = 1)
checkmate::assert_flag(quiet)
alert("** Tidying the references/citations **",
combined_styles = c("silver"), abort = quiet)
x <- x %>% dplyr::mutate(dplyr::across(.fns = stringr::str_squish))
if (all(c("type", "work_type") %in% names(x), na.rm = TRUE)) {
for (i in sqlr::ris_types) {
x <- x %>% dplyr::mutate(
type = dplyr::if_else(
is.na(type) & !is.na(work_type) &
stringr::str_detect(work_type, i$pattern),
i$type,
type,
missing = as.character(NA)))
}
}
if ("doi" %in% names(x)) {
# About the DOI pattern: <https://bit.ly/3eA2By0>.
pattern_doi <- "10.\\d{4,9}/[-._;()/:a-z0-9A-Z]+"
x <- x %>%
dplyr::mutate(doi = stringr::str_extract(data$doi, pattern_doi))
}
if ("doi" %in% names(x)) {
# About the DOI pattern: <https://bit.ly/3eA2By0>.
pattern_doi <- "10.\\d{4,9}/[-._;()/:a-z0-9A-Z]+"
x <- x %>%
dplyr::mutate(doi = stringr::str_extract(doi, pattern_doi))
}
if ("pmid" %in% names(x)) {
pattern_pmid <- "^\\d+$"
x <- x %>%
dplyr::mutate(pmid = stringr::str_extract(pmid, pattern_pmid))
}
if ("year" %in% names(x)) {
x <- x %>% dplyr::mutate(
year = stringr::str_extract(year, "^\\d{4}"))
}
if ("title" %in% names(x)) {
x <- x %>% dplyr::mutate(
title = dplyr::case_when(
is.na(title) & !is.na(book_title) ~ book_title,
TRUE ~ title))
}
if (all(c("start_page", "end_page", "pagination") %in% names(x),
na.rm = TRUE)) {
x <- x %>% dplyr::mutate(
start_page = dplyr::case_when(
is.na(start_page) & !is.na(pagination) &
stringr::str_detect(pagination, "-") ~
stringr::str_extract(pagination, "^.+(?=-)"),
is.na(start_page) & !is.na(pagination) ~ pagination,
TRUE ~ start_page),
end_page = dplyr::case_when(
is.na(end_page) & !is.na(pagination) &
stringr::str_detect(pagination, "-") ~
stringr::str_extract(pagination, "(?<=-).+"),
TRUE ~ end_page))
}
cols <- c("type", "doi", "pmid", "author", "year", "title",
"abstract", "keyword", "journal", "place_published", "volume",
"issue", "start_page", "end_page", "publisher", "standard_number",
"author_info", "author_id", "secondary_author", "tertiary_author",
"editor", "corporate_author", "subsidiary_author", "short_title",
"secondary_title", "tertiary_title", "journal_abbreviation",
"book_title", "work_type", "publication_status", "language",
"database", "length", "provider", "file")
cols <- cols[which(cols %in% names(x))]
devtools::load_all(".")
x <- tidy_reference(raw, quiet)
after_tidy <- x
x <- identify_duplicates(x, quiet)
x <- x %>% dplyr::mutate(criteria_id = as.character(NA),
trial_id = as.character(NA))
x <- x %>% dplyr::relocate(criteria_id, trial_id)
x <- x %>% dplyr::arrange(dplyr::desc(length))
temp <- x %>% dplyr::select(length)
"length" %in% names(x)
names(x)
devtools::load_all(".")
x <- tidy_reference(x, quiet)
after_tidy <- x
names(x)
x <- identify_duplicates(x, quiet)
temp <- head(x, 10)
View(temp)
temp <- tail(x, 10)
temp <- tail(x, 15)
unique(x$criteria_id)
unique(x$trial_id)
temp <- tail(dplyr::arrange(x, year), 15)
temp <- tail(dplyr::arrange(x, dplyr::desc(year)), 15)
temp <- tail(dplyr::arrange(x, dplyr::desc(year)), 30)
head(x$year)
?dplyr::arrange
temp <- head(dplyr::arrange(x, dplyr::desc(year)), 30)
temp <- head(dplyr::arrange(x, dplyr::desc(year)), 50)
length(which(x$criteria_id == "DUP")
)
length(which(x$criteria_id == "DUP"))
length(which(x$criteria_id == "DUP")) / 21184
head(x$length)
length(names(x))
after_dup <- x
x <- assign_ref_ids(x, package, quiet)
devtools::load_all(".")
x <- assign_ref_ids(x, package, quiet)
devtools::load_all(".")
x <- assign_ref_ids(x, package, quiet)
temp <- head(x, 10)
which(is.na(x$source_id))
!length(which(is.na(x$source_id))) == 0
!length(which(is.na(x$search_id))) == 0
after_id <- x
devtools::load_all(".")
x %>% write_reference(package = package, quiet = quiet)
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
use_pipe()
devtools::load_all(".")
?`:=`
devtools::load_all(".")
devtools::install()
tools::checkRdaFiles()
devtools::load_all(".")
devtools::load_all(".")
tools::checkRdaFiles()
?tools::checkRdaFiles()
tools::checkRdaFiles(".\data")
tools::checkRdaFiles("./data")
devtools::load_all(".")
source('C:/Midia/GitHub/sqlr/data-raw/provider_tags.R')
provider_tags(TRUE)
devtools::load_all(".")
query("Lorem", "Ipsum, dolor", "sit", provider = "PubMed",
constraint = c("title", "abstract"), clipboard = FALSE)
query("Lorem", "AND", "Ipsum", "NOT", "dolor", provider = "EMBASE",
constraint = c("title", "abstract"), clipboard = FALSE)
query(keyword_set(1, "english"), "AND", keyword_set(2, "english"),
provider = "wos", constraint = c("title", "abstract", "keyword"))
pattern <- "^sheets$|^reference$|^document$"
name <- stringr::str_subset(names(sheets), pattern, negate = TRUE)
name
names(sheets)
devtools::load_all(".")
read_sheet("sheet")
read_sheet("sheets")
read_sheet("reference")
read_sheet("document")
read_sheet("domain")
pattern <- "^sheets$|^reference$|^document$|^trial_"
stringr::str_detect("trial_nr1", pattern)
stringr::str_detect("trial", pattern)
stringr::str_subset(names(sheets), pattern, negate = TRUE)
write_metadata("1x6Aj8cXl9qFtpXq48Q6zdmT-w9EEqNG1iVQcKVRhgKM")
devtools::load_all(".")
stringr::str_subset(names(sheets), pattern, negate = TRUE)
names(sheets)
sheets
sheets[1]
sheets[-1]
vapply(sheets, function(X) x$type == "Entity")
vapply(sheets, function(X) x$type == "Entity", logical(1))
vapply(sheets, function(x) x$type == "Entity", logical(1))
sheets[-vapply(sheets, function(x) x$type == "Entity", logical(1))]
sheets[!vapply(sheets, function(x) x$type == "Entity", logical(1))]
sheets[vapply(sheets, function(x) x$type == "Entity", logical(1))]
detect <- function(x) {
x$type == "Entity" || x$name %in% c("reference", "document")
}
detect <- function(x) {
tolower(x$type) == "entity" ||
!tolower(x$name) %in% c("reference", "document")
}
sheets[vapply(sheets, detect, logical(1))]
vapply(sheets, detect, logical(1))
detect <- function(x) {
tolower(x$type) == "entity" &&
!tolower(x$name) %in% c("reference", "document")
}
vapply(sheets, detect, logical(1))
name <- "test"
sheets <- sheets[vapply(sheets, detect, logical(1))]
(any(!name %in% names(sheet), na.rm = TRUE))
(any(!name %in% names(sheets), na.rm = TRUE))
name
(all(name %in% names(sheets), na.rm = TRUE))
name <- "criteria"
(all(name %in% names(sheets), na.rm = TRUE))
name <- c("criteria", "test")
(all(name %in% names(sheets), na.rm = TRUE))
devtools::load_all(".")
test <- read_sheet("sheets")
test
names(sheets)
devtools::load_all(".")
devtools::load_all(".")
temp <- head(reference)
View(temp)
nrow(dplyr::filter(reference, criteria_id = "DUP"))
nrow(dplyr::filter(reference, criteria_id == "DUP"))
9028 / nrow(reference)
devtools::load_all(".")
devtools::load_all(".")
temp <- head(reference)
View(temp)
?installr::updateR()
?installr::updater()
installr::updateR()
install.packages("emojifont")
devtools::install()
install.packages("bibliometrix")
library(bibliometrix)
biblioshiny()
library(bibliometrix)
file <- "https://www.bibliometrix.org/datasets/savedrecs.bib"
M <- convert2df(file = file, dbsource = "isi", format = "bibtex")
results <- biblioAnalysis(M, sep = ";")
sqlr::raw_data()
sqlr::raw_data("reference")
sqlr::raw_data("reference", "2021-04-27_reference_pubmed_en_1-2869.zip"  )
file <- sqlr::raw_data("reference", "2021-04-27_reference_pubmed_en_1-2869.zip"  )
file <- utils::unzip(file, tempdir())
file <- sqlr::raw_data("reference", "2021-04-27_reference_pubmed_en_1-2869.zip"  )
file <- utils::unzip(file)
?utils::unzip
file <- sqlr::raw_data("reference", "2021-04-27_reference_pubmed_en_1-2869.zip"  )
file <- utils::unzip(file, exdir = tempdir())
M <- convert2df(file = file, dbsource = "pubmed", format = "txt")
M <- convert2df(file = file, dbsource = "pubmed", format = "pubmed")
test <- head(M)
View(test)
results <- biblioAnalysis(M, sep = ";")
S <- summary(object = results, k = 10, pause = FALSE)
plot(x = results, k = 10, pause = FALSE)
results$Articles[1]
results$Articles[2]
View(results)
M$CR[1]
M$CR[2]
M$CR[6]
tail(M$CR)
unique(M$CR)
M$AU_UN_NR[1]
DF <- dominance(results, k = 10)
DF
topAU <- authorProdOverTime(M, k = 10, graph = TRUE)
topAU
# Create a country collaboration network
M <- metaTagExtraction(M, Field = "AU_CO", sep = ";")
NetMatrix <- biblioNetwork(M, analysis = "collaboration", network = "countries", sep = ";")
# Plot the network
net=networkPlot(NetMatrix, n = dim(NetMatrix)[1], Title = "Country Collaboration", type = "circle", size=TRUE, remove.multiple=FALSE,labelsize=0.7,cluster="none")
test <- head(M)
View(test)
# Create keyword co-occurrences network
NetMatrix <- biblioNetwork(M, analysis = "co-occurrences", network = "keywords", sep = ";")
# Plot the network
net=networkPlot(NetMatrix, normalize="association", weighted=T, n = 30, Title = "Keyword Co-occurrences", type = "fruchterman", size=T,edgesize = 5,labelsize=0.7)
devtools::load_all(".")
require_pkg("test")
require_pkg("base")
devtools::load_all(".")
usethis::use_github_action("test-coverage-pak")
?install.packages
devtools::load_all(".")
require_pkg("test")
require_pkg("test", "test2")
devtools::load_all(".")
require_pkg("test", "test2")
require_pkg("test", "test2", "test3")
require_pkg("test", "test2", "base")
require_pkg("mctq", "test2", "base")
require_pkg("mctq", "test2", "base")
require_pkg("mctq", "test2", "ggplot")
require_pkg("mctq", "test2", "ggplot2")
checkmate::test_atomic(character())
checkmate::test_atomic(numeric())
checkmate::test_atomic(list())
args(checkmate::test_atomic)
devtools::load_all(".")
sheets$sheets
sheets
sex <- "male"
age <- 38
sex == "male"
sex == "female"
age >= 18
age == 18
sex == "masculilno" && age >= 18
sex == "male" && age >= 18
sex == "male" && age <= 18
sex == "male" || age <= 18
sex <- "male"
age <- 38
sex == "male"
age >= 18
sex == "male" && age <= 18
sex == "male" || age <= 18
devtools::load_all(".")
sheets
devtools::install()
View(reference)
nrow(dplyr::filter(reference, criteria_id == "DUP")) +
sheet_nrow("trial_nr1") == nrow(reference)}
nrow(dplyr::filter(reference, criteria_id == "DUP")) +
sheet_nrow("trial_nr1") == nrow(reference)
read_sheet("trial_nr2-id")
read_sheet("trial_nr2-ld1")
?dplyr::across
?dplyr::ends_with
?dplyr::across
cli::cli_abort("test")
rlang::last_error()
stop("test")
cli::cli_alert_danger("test")
cli::cli_alert("test")
cli::cli_abort("test", "2")
cli::cli_abort(paste0("test", "2"))
cli::cli_abort(paste0(
"The 'reference' dataset ended with no rows after the cleaning",
"process."))
}
cli::cli_abort(paste0(
"The 'reference' dataset ended with no rows after the cleaning",
"process."))
cli::cli_abort(paste0(
"The 'reference' dataset ended with no rows after the cleaning ",
"process."))
stop("The 'reference' dataset ended with no rows after the cleaning ",
"process.")
cli::cli_abort(paste0(
"The 'reference' dataset ended with no rows after the cleaning ",
"process."), wrap = TRUE)
cli::cli_abort(paste0(
"The 'reference' dataset ended with no rows after the cleaning ",
"process."))
cli_text(cli:::lorem_ipsum())
cli::cli_text(cli:::lorem_ipsum())
cli::cli_abort(paste0(
"The 'reference' dataset ended with no rows after the cleaning ",
"process."))
cli::ansi_with_hidden_cursor(demo_spinners("dots"))
cli::ansi_with_hidden_cursor(cli::demo_spinners("dots"))
data <- head(reference)
reference["criteria_id"]
reference[["criteria_id"]]
data[["criteria_id"]]
data[["criteria_id"]] == data[["criteria_id"]]
identical(data[["criteria_id"]], data[["criteria_id"]])
?identical
cli::cli_alert_warning("{i} was not updated.")
i <- "criteri_id"
cli::cli_alert_warning("{i} was not updated.")
single_quote_("a")
devtools::load_all(".")
single_quote_("a")
data$criteria_id
data$criteria_id[which(!is.na(data$criteria_id))]
rm_na(c(NA, 1))
a <- "test"
cli::cli_alert_success(a)
cli::cli_alert("test")
shush(cli::cli_alert("test"))
shush(cli::cli_alert("test"), FALSE)
args(shush)
trial_name <- paste0("trial_", tolower("DUP"))
cli::cli_abort(paste0("{single_quote_(trial_name)}, was not found ",
"in the 'sheets' table."))
cli::cli_alert_success(paste0("{.field single_quote(i)} was updated. ",
"{changes} records added."))
changes <- 12
cli::cli_alert_success(paste0("{.field single_quote(i)} was updated. ",
"{changes} records added."))
cli::cli_alert_success(paste0("{.field {single_quote(i)}} was updated. ",
"{changes} records added."))
cli::cli_alert_success(paste0("{.field {single_quote_(i)}} was updated. ",
"{changes} records added."))
cli::cli_alert_success(paste0("{.field {single_quote_(i)}} was ",
"updated. {.strong {changes}} records added."))
cli::cli_alert_success(paste0(
"{.field {single_quote_(i)}} was updated. ",
"{.strong {changes}} records added."))
cli::cli_alert_success(paste0(
"{cli::col_blue(single_quote_(i))}} was updated. ",
"{.strong {changes}} records added."))
cli::cli_alert_success(paste0(
"{cli::col_blue(single_quote_(i))} was updated. ",
"{.strong {changes}} records added."))
cli::cli_alert_success(paste0(
"{cli::col_blue(single_quote_(i))} was updated. ",
"{cli::col_green(changes)} records added."))
cli::cli_alert_success(paste0(
"{cli::col_blue(single_quote_(i))} was updated. ",
"{.strong {cli::col_green(changes)}} records added."))
cli::cli_alert_success(paste0(
"{.strong {cli::col_blue(single_quote_(i))}} was updated. ",
"{.strong {cli::col_green(changes)}} records added."))
cli::cli_alert_warning(paste0(
"{.strong {cli::col_blue(single_quote_(i))}} was not updated. ",
"{.strong {cli::col_red('0')}} records added."))
cli::cli_alert_warning(
"{.strong {cli::col_blue(single_quote_(i))}} was not updated.")
cli::cli_alert_warning(paste0(
"{.strong {cli::col_blue(single_quote_(i))}} was ",
"{.strong{cli::col_red(not)}} updated."))
cli::cli_alert_warning(paste0(
"{.strong {cli::col_blue(single_quote_(i))}} was ",
"{.strong {cli::col_red(not)}} updated."))
cli::cli_alert_warning(paste0(
"{.strong {cli::col_blue(single_quote_(i))}} was ",
"{.strong {cli::col_red('not')}} updated."))
args(shush)
usethis::use_r("write_reference")
quiet <- FALSE
shush(cli::cli_alert(
"Writing the 'reference' table to Google Spreadsheets"), quiet = quiet)
shush(cli::cli_alert("Writing the 'reference' table to the package."),
quiet = quiet)
cli::cli_alert("\n", "Run (in order):\n\n",
"devtools::document() [Ctrl + Shift  + D]\n",
"devtools::load_all() [Ctrl + Shift  + L]")
cli::cli_alert(paste0("\n", "Run (in order):\n\n",
"devtools::document() [Ctrl + Shift  + D]\n",
"devtools::load_all() [Ctrl + Shift  + L]"))
cli::cli_alert_info(paste0(
"Run (in order):\n\n",
"devtools::document() [Ctrl + Shift  + D]\n",
"devtools::load_all() [Ctrl + Shift  + L]"))
cli::cli_alert_info(cli::col_red(paste0(
"{.strong Run (in order):\n\n",
"devtools::document() [Ctrl + Shift  + D]\n",
"devtools::load_all() [Ctrl + Shift  + L]}")))
cli::cli_alert_info(paste0(
"{.strong {cli::col_red('Run (in order)')}:\n\n",
"devtools::document() [Ctrl + Shift  + D]\n",
"devtools::load_all() [Ctrl + Shift  + L]}"))
cli::cli_alert_info(paste0(
"{.strong {cli::col_red('Run (in order)')}}:\n\n",
"{.strong devtools::document() [Ctrl + Shift  + D]\n",
"devtools::load_all() [Ctrl + Shift  + L]}"))
message <- paste0("\n",
crayonize("This may take a while. Please be patient."),
emojinize("hourglass_flowing_sand", left_space = TRUE),
"\n\n")
if (isFALSE(quiet)) cat(message)
data.frame(a = 1, b = 1)
cli::cli_abort(paste0("{single_quote_(trial_name)}, was not found ",
"in the {cli::col_blue('sheets') table."))
cli::cli_abort(paste0("{single_quote_(trial_name)}, was not found ",
"in the {cli::col_blue('sheets')} table."))
cli::cli_abort(paste0("{single_quote_(trial_name)} was not found ",
"in the {cli::col_blue('sheets')} table."))
cli::cli_abort(paste0("{single_quote_(trial_name)} was not found ",
"in the {cli::col_blue('sheets')} table."))
cli::cli_abort(paste0("{single_quote_(trial_name)} was not found ",
"in the {cli::col_blue('sheets')} table."))
cli::cli_abort(paste0("{single_quote_(cli::col_red(trial_name))} ",
"was not found in the ",
"{cli::col_blue('sheets')} table."))
cli::cli_abort(paste0("{cli::col_red(trial_name)} ",
"was not found in the ",
"{cli::col_blue('sheets')} table."))
trial_id <- "DUP"
cli::cli_abort(paste0("{cli::col_red(trial_id)} ",
"was not found in the ",
"{cli::col_blue('trial')} table."))
cli::cli_abort(paste0("{cli::col_red(toupper(trial_id))} ",
"was not found in the ",
"{cli::col_blue('trial')} table."))
cli::cli_abort(paste0(
"{cli::col_red(trial_name)} was not found in the ",
"{cli::col_blue('sheets')} table."))
cli::cli_abort(paste0(
"{cli::col_red(toupper(trial_id))} was not found in the ",
"{cli::col_blue('trial')} table."))
cli::cli_abort(paste0(
"The {cli::col_green(toupper('reference'))} ",
"dataset ended with no rows after the cleaning process."))
cli::cli_abort(paste0(
"The {cli::col_green('reference')} ",
"dataset ended with no rows after the cleaning process."))
trial_x <- "DUP"
trial_id <- "NR1"
cli::cli_abort(paste0(
"The {cli::col_red(trial_x)} trial_id, i.e. the trial_id ",
"that comes before {cli::col_red(trial_id)} is not ",
"approved in the 'trial' table. This trial must be approved ",
"and the 'reference' table must be updated before running ",
"{cli::col_blue('write_trial()')}."))
cli::cli_abort(paste0(
"The {cli::col_red(trial_x)} trial_id, i.e. the trial_id ",
"that comes before {cli::col_red(trial_id)} is not ",
"approved in the {cli::col_green('trial')} table. ",
"This trial must be approved and the ",
"{cli::col_green('reference')} table must be updated ",
"before running {cli::col_blue('write_trial()')}."))
cli::cli_abort(paste0(
"The {cli::col_red(trial_x)} trial_id, i.e. the trial_id ",
"that comes before {cli::col_red(trial_id)} is not ",
"approved in the {cli::col_grey('trial')} table. ",
"This trial must be approved and the ",
"{cli::col_grey('reference')} table must be updated ",
"before running {cli::col_blue('write_trial()')}."))
devtools::install()
